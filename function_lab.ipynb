{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06deff8f-64f5-4621-84eb-94b3b18c7e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.14.2 requires protobuf<7.0,==6.31.1, but you have protobuf 5.29.5 which is incompatible.\n",
      "kfp-pipeline-spec 2.14.0 requires protobuf<7.0,==6.31.1, but you have protobuf 5.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --quiet --user google-cloud-aiplatform==1.88.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a950e13-eb97-46a0-8793-20664917ee01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ab9e51-b388-4025-b3ae-f102a04df5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-03-b2ab7d4155ac\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = ! gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "print(PROJECT_ID)\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df7129f-791a-4611-ab7f-d34822a27ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27379ca1-1e1f-4abd-b9b9-cd69ba4cd1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from google.generativeai.tool import Tool, FunctionDeclaration\n",
    "\n",
    "# Define the Python functions first\n",
    "def add(num1, num2):\n",
    "  \"\"\"Adds two numbers, prints the result, and returns it.\"\"\"\n",
    "  total = num1 + num2\n",
    "  print(\"Calling add function\")\n",
    "  return total\n",
    "\n",
    "def multiply(num1, num2):\n",
    "  \"\"\"Multiplies two numbers, prints the result, and returns it.\"\"\"\n",
    "  product = num1 * num2\n",
    "  print(\"Calling multiply function\")\n",
    "  return product\n",
    "\n",
    "# Define the math Tool for the model\n",
    "math_tool = Tool(\n",
    "    function_declarations=[\n",
    "        FunctionDeclaration(\n",
    "            name=\"add\",\n",
    "            description=\"Adds two numbers.\",\n",
    "            parameters={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"num1\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The first number.\"\n",
    "                    },\n",
    "                    \"num2\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The second number.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"num1\", \"num2\"]\n",
    "            }\n",
    "        ),\n",
    "        FunctionDeclaration(\n",
    "            name=\"multiply\",\n",
    "            description=\"Multiplies two numbers.\",\n",
    "            parameters={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"num1\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The first number.\"\n",
    "                    },\n",
    "                    \"num2\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The second number.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"num1\", \"num2\"]\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b24589b8-d1b5-4d70-84f9-82d4299bcd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import google.generativeai as genai\n",
    "\n",
    "# NOTE: This assumes the 'math_tool' from the previous step is already defined.\n",
    "\n",
    "# Define the system instructions for the model\n",
    "system_instructions = \"\"\"\n",
    "You are a helpful assistant. Fulfill the user's instructions, including telling jokes.\n",
    "When asked to add or multiply numbers, you must call the provided functions.\n",
    "You may call one function after the other if needed.\n",
    "After calling a function, repeat the final numerical result to the user.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the Generative Model\n",
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    tools=[math_tool],\n",
    "    generation_config={\"temperature\": 0},\n",
    "    system_instruction=system_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de6428d7-16aa-4b1c-b90b-a49453e7a712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab7f2afe-45fb-4c91-8597-1d226b31c1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"add\": add,\n",
    "    \"multiply\": multiply,\n",
    "}\n",
    "def handle_response(response):\n",
    "    \"\"\"Handles the model's response, calling functions if requested.\"\"\"\n",
    "\n",
    "    # If there is a function call, extract the first one.\n",
    "    # Otherwise, print the model's text response and stop.\n",
    "    if response.candidates[0].function_calls:\n",
    "        function_call = response.candidates[0].function_calls[0]\n",
    "    else:\n",
    "        print(response.text)\n",
    "        return\n",
    "\n",
    "    # Check if the requested function is one we have defined\n",
    "    if function_call.name in available_functions:\n",
    "        # Select the correct function from our dictionary\n",
    "        function_to_call = available_functions[function_call.name]\n",
    "        \n",
    "        # Extract the arguments from the model's request\n",
    "        args = {key: value for key, value in function_call.args.items()}\n",
    "        \n",
    "        # Call the local Python function with the provided arguments\n",
    "        function_response = function_to_call(**args)\n",
    "        \n",
    "        # Send the function's result back to the model so it can formulate a text response\n",
    "        api_response = chat.send_message(\n",
    "            Part.from_function_response(\n",
    "                name=function_call.name,\n",
    "                response={\"result\": function_response},\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Make a recursive call to handle the model's next response\n",
    "        handle_response(api_response)\n",
    "\n",
    "    else:\n",
    "        # This would happen if the model tries to call a function you haven't defined\n",
    "        print(f\"Error: Model tried to call unknown function '{function_call.name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8436a29e-8412-4d81-9781-123cb8e3ac2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Tell me a joke?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e48b206-000a-44a7-b4bb-fd395d5d7fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling multiply function\n",
      "You have 112 slices.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"I have 7 pizzas each with 16 slices. How many slices do I have?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dcd5a38-4a0d-48c7-ae23-d1f7641cc470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "They brought 7 pizzas together.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. How many pizzas did they bring together?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee6216fe-a689-43b1-a6b2-cbc33e06af66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 3 and 4 is 7.\n",
      "The product of 7 and 16 is 112.\n",
      "There are 112 slices in total.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. There are 16 slices per pizza. How many slices are there?\")\n",
    "handle_response(response)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e60dd8b-64a4-4928-bef3-5f9e2ce8ee4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "Calling multiply function\n",
      "There are 112 slices in total.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. There are 16 slices per pizza. How many slices are there?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587ba54-b910-4eec-9226-e5fac97b6205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m132",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m132"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
